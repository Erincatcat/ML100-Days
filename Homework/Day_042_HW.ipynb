{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型四步驟\n",
    "在 Scikit-learn 中，建立一個機器學習的模型其實非常簡單，流程大略是以下四個步驟\n",
    "\n",
    "1. 讀進資料，並檢查資料的 shape (有多少 samples (rows), 多少 features (columns)，label 的型態是什麼？)  \n",
    "**使用 pandas 讀取 .csv 檔：pd.read_csv  \n",
    "使用 numpy 讀取 .txt 檔：np.loadtxt  \n",
    "使用 Scikit-learn 內建的資料集：sklearn.datasets.load_xxx  \n",
    "檢查資料數量：data.shape (data should be np.array or dataframe)**  \n",
    "2. 將資料切為訓練 (train) / 測試 (test)  \n",
    "train_test_split(data)  \n",
    "3. 建立模型，將資料 fit 進模型開始訓練  \n",
    "clf = DecisionTreeClassifier()  \n",
    "clf.fit(x_train, y_train)  \n",
    "4. 將測試資料 (features) 放進訓練好的模型中，得到 prediction，與測試資料的 label (y_test) 做評估  \n",
    "clf.predict(x_test)  \n",
    "accuracy_score(y_test, y_pred)  \n",
    "f1_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "# 如果是分類問題，請使用 DecisionTreeClassifier，若為回歸問題，請使用 DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9736842105263158\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.         0.01796599 0.05992368 0.92211033]\n"
     ]
    }
   ],
   "source": [
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "1. 試著調整 DecisionTreeClassifier(...) 中的參數，並觀察是否會改變結果？  \n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**調整 DecisionTreeClassifier(...) 中的參數**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9736842105263158\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.         0.         0.06058349 0.93941651]\n"
     ]
    }
   ],
   "source": [
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier(\n",
    "        criterion = 'entropy',   #gini(default)或者entropy\n",
    "        max_depth = 3,           #決策樹最大深度，不設定則不限制樹的深度。樣本或特徵少時可不設定，樣本或特徵多時，推薦可10-100之間。\n",
    "        min_samples_split = 20,  #內部節點需再劃分之最小樣本數，樣本數不大時可不設定。default=2\n",
    "        min_samples_leaf = 5,    #葉節點最小樣本數。default=1\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→Accuracy無影響，但對feature importance有影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Breast_cancer = datasets.load_breast_cancer()\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breast_cancer**  -  DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Accuracy:  0.9090909090909091\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.         0.         0.         0.         0.0092534  0.\n",
      " 0.         0.         0.00991435 0.         0.00660957 0.\n",
      " 0.         0.00494089 0.         0.         0.         0.\n",
      " 0.00941052 0.         0.         0.059601   0.75416545 0.04898212\n",
      " 0.05147346 0.00793148 0.         0.03771776 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Breast_cancer.data.shape)\n",
    "print(Breast_cancer.feature_names)\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(Breast_cancer.data, Breast_cancer.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "與線性迴歸的結果[Day_038_HW.ipynb](https://github.com/Erincatcat/ML100-Days/blob/master/Homework/Day_038_HW.ipynb)相比，accuracy從0.96下降至0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Acuuracy:  0.9111111111111111\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.04440705 0.         0.         0.         0.         0.06142526\n",
      " 0.         0.         0.         0.38107601 0.         0.12444169\n",
      " 0.38865   ]\n"
     ]
    }
   ],
   "source": [
    "print(wine.data.shape)\n",
    "print(wine.feature_names)\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)\n",
    "\n",
    "print(wine.feature_names)\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "與線性迴歸的結果[Day_038_HW.ipynb](https://github.com/Erincatcat/ML100-Days/blob/master/Homework/Day_038_HW.ipynb)相比，accuracy從1下降至0.911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課後補充:\n",
    "\n",
    "可安裝額外的套件 graphviz，畫出決策樹的圖形幫助理解模型分類的準則。  \n",
    "詳細參考文章[Creating and Visualizing Decision Trees with Python](https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
